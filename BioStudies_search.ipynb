{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea of automizing the search for RNA-seq data within BioStudies. \n",
    "### many cases:\n",
    "### - ENA got the data (fastq (i need to calc it myself somewhen ...))\n",
    "### - count matrix is attached to files \n",
    "### - probably more of this ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from scipy.io import mmread\n",
    "from utils.helper import get_negative_values, METADATA_COLS, reorder_columns_by_metadata_and_gene_counts, convert_gene_names_to_ensembl, clean_age\n",
    "from utils.plotting import violinplot_overall, scatter_plot, manhattanplot\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_get_study=\"https://www.ebi.ac.uk/biostudies/api/v1/studies/\"\n",
    "\n",
    "ena_url_filereport_ERP = \"https://www.ebi.ac.uk/ena/portal/api/filereport?result=read_run&accession=\"\n",
    "ena_url_query_end = \"&format=json&fields=study_accession,secondary_study_accession,sample_accession,secondary_sample_accession,experiment_accession,run_accession,submission_accession,tax_id,scientific_name,instrument_platform,instrument_model,library_name,nominal_length,library_layout,library_strategy,library_source,library_selection,read_count,base_count,center_name,first_public,last_updated,experiment_title,study_title,study_alias,experiment_alias,run_alias,fastq_bytes,fastq_md5,fastq_ftp,fastq_aspera,fastq_galaxy,submitted_bytes,submitted_md5,submitted_ftp,submitted_aspera,submitted_galaxy,submitted_format,sra_bytes,sra_md5,sra_ftp,sra_aspera,sra_galaxy,sample_alias,broker_name,sample_title,nominal_sdev,first_created,bam_ftp,bam_bytes,bam_md5\"\n",
    "ena_tsv_download_query_end= '&fields=study_accession,sample_accession,experiment_accession,run_accession,tax_id,instrument_platform,instrument_model,library_strategy,base_count,center_name,experiment_title,fastq_ftp,submitted_ftp,sra_ftp,sample_title&format=tsv&download=true&limit=0'\n",
    "ena_json_query_end= '&fields=study_accession,sample_accession,experiment_accession,run_accession,tax_id,instrument_platform,instrument_model,library_strategy,base_count,center_name,experiment_title,fastq_ftp,submitted_ftp,sra_ftp,sample_title&format=json&limit=0'\n",
    "\n",
    "\n",
    "###### ENA handling\n",
    "#TODO check if this is even needed. right now the endpoint does not work anyways\n",
    "# maybe we can also just directly download the TSV and the downloading script (Download all button for fastq files... this then downloads a lot of data if we shall execute it)\n",
    "# Source https://www.ebi.ac.uk/ena/browser/api/swagger-ui/index.html#/content-controller/getSummary \n",
    "\n",
    "def get_ena_link(study_json):\n",
    "    ena_links = []\n",
    "    for link in study_json.get('section', {}).get('links', []):\n",
    "        if link.get('url').startswith('ERP'):\n",
    "            ena_links.append(link.get('url'))\n",
    "    return ena_links\n",
    "\n",
    "def download_ena_tsv(ena_accession):\n",
    "    response = requests.get(ena_url_filereport_ERP + ena_accession + ena_tsv_download_query_end)\n",
    "    if response.status_code == 200:\n",
    "        file_path = os.path.join(ena_accession, f'{ena_accession}.tsv')\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded and saved as '{file_path}'.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "\n",
    "### this is same as the tsv but in json format\n",
    "def get_ena_fastq_ftp_download_links(ena_accession):\n",
    "    fastq_links = []\n",
    "\n",
    "    response = requests.get(ena_url_filereport_ERP + ena_accession + ena_json_query_end)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for sample in data:\n",
    "            sample_ftp_links = sample['fastq_ftp'].split(';')\n",
    "            fastq_links = fastq_links + sample_ftp_links\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "\n",
    "    file_path = os.path.join(ena_accession, f'{ena_accession}_fastq_ftp_links.txt')\n",
    "    with open(file_path, 'w') as f:\n",
    "        for link in fastq_links:\n",
    "            f.write(link + '\\n')\n",
    "\n",
    "\n",
    "#TODO delete?\n",
    "def get_filereport(ena_accession):\n",
    "    ena_accession_primary = []\n",
    "\n",
    "    requests.get(ena_url_filereport_ERP + ena_accession + ena_url_filereport_ERP)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # now as we have gotten to the overview: \n",
    "        # TODO here we could automate the download for every sample ID in the filereport (without limit should show it all)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "        \n",
    "        \n",
    "def ena_handling(ena_accession):\n",
    "    os.makedirs('ENA' + ena_accession, exist_ok=True)\n",
    "    print(f\"Directory '{ena_accession}' created or already exists.\")\n",
    "\n",
    "    download_ena_tsv(ena_accession)\n",
    "    get_ena_fastq_ftp_download_links(ena_accession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biosample_query_response(biosample_url):\n",
    "    response = requests.get(biosample_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "        return 0\n",
    "        \n",
    "        \n",
    "\n",
    "def is_useful_file(filename):\n",
    "    filename = filename.lower()\n",
    "    \n",
    "    # Check if \"count\" is in the filename or if it ends with .fastq or .fq\n",
    "    if \"count\" in filename:\n",
    "        return True\n",
    "    \n",
    "    if filename.endswith(\".fastq\") or filename.endswith(\".fq\"):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def filter_study_characteristics(study_json):\n",
    "    useful_files = []\n",
    "    is_useful = False\n",
    "    # Navigate to the 'Source Characteristics' subsection\n",
    "    for subsection in study_json.get('section', {}).get('subsections', []):\n",
    "        #TODO bugfix, in example the first is an array ... \n",
    "        if type(subsection) is not dict:\n",
    "            continue\n",
    "        if subsection.get('type') == 'Source Characteristics':\n",
    "            organism = None\n",
    "            organism_part = None\n",
    "            for attribute in subsection.get('attributes', []):\n",
    "                if attribute.get('name') == 'Organism':\n",
    "                    organism = attribute.get('value')\n",
    "                elif attribute.get('name') == 'Organism part':\n",
    "                    organism_part = attribute.get('value')\n",
    "            # Check if conditions are met\n",
    "            if organism == \"Homo sapiens\" and organism_part in [\"blood\", \"whole blood\", \"PBMC\"]:\n",
    "                is_useful = True\n",
    "            \n",
    "        #TODO this is prone, sometimes processed data appears under another hierarchy \n",
    "        if subsection.get('type') == 'Processed Data':\n",
    "            for files in subsection.get('files', []):\n",
    "                if is_useful_file(files.get('path')):\n",
    "                    useful_files.append(files.get('path'))\n",
    "            \n",
    "    return is_useful, useful_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE here i want to store some possible search queries, I produced the queries there and copied with inspect tool of the browser:  https://www.ebi.ac.uk/biostudies/ \n",
    "\n",
    "#LIMIT\n",
    "query_minimal = '%28RNA-seq+or+rnaseq%29+AND+%28human+or+%27homo+sapiens%27%29'   # ~3k results\n",
    "query_medium = '%28RNA-seq+or+rnaseq%29+AND+%28human+or+%27homo+sapiens%27%29+AND+%28blood+OR+%27whole+blood%27+OR+PBMC%29+AND+NOT+%27single+cell%27+AND+NOT+%27cord+blood%27' # 630 results\n",
    "query_long=\"%28rna-seq+OR+rnaseq%29+AND+%28human+OR+%22homo+sapiens%22%29+AND+%28blood+OR+%22whole+blood%22+OR+PBMC%29+AND+%28%22bulk%22%29+AND+NOT+%28sc+OR+%22single-cell%22%29+AND+NOT+DNA\"\n",
    "## pageSize 100 is max\n",
    "current_page = 1\n",
    "url_get_all = f\"https://www.ebi.ac.uk/biostudies/api/v1/search?pageSize=100&page={str(current_page)}&query=\"\n",
    "\n",
    "query = query_medium\n",
    "\n",
    "##\n",
    "url = url_get_all + query\n",
    "print(url)\n",
    "data = get_biosample_query_response(url)\n",
    "hits = data.get(\"hits\", [])\n",
    "total_hits = data.get(\"totalHits\")\n",
    "\n",
    "print(f'{len(hits)} / {total_hits}')\n",
    "\n",
    "filtered_hits = [hit for hit in hits if \"GEO\" not in hit[\"accession\"]]\n",
    "print(f'{len(filtered_hits)}')\n",
    "# Display the filtered results\n",
    "for hit in filtered_hits:\n",
    "    \n",
    "    response = requests.get(url_get_study + hit['accession'])\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        is_useful, useful_files = filter_study_characteristics(data)\n",
    "        print(f\"Useful: {is_useful}\")           \n",
    "        if is_useful:\n",
    "            print(\"=\"*50)            \n",
    "            print(f\"Accession: {hit['accession']}\")\n",
    "            print(f\"Title: {hit['title']}\")\n",
    "            print(f\"Views: {hit['views']}\")\n",
    "            print(f\"Useful files: {useful_files} for {hit}\")\n",
    "            print(\"=\"*50)            \n",
    "\n",
    "            ena_accession = get_ena_link(data)\n",
    "            print(f'{ena_accession}')\n",
    "        \n",
    "            #NOTE ENA handling \n",
    "            ena_handling(ena_accession)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "    \n",
    "    if total_hits - len(hits) > 0:\n",
    "        current_page += 1\n",
    "        #TODO next 100 pages ... \n",
    "        \n",
    "        \n",
    "    time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

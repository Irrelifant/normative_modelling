{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea of automizing the search for RNA-seq data within BioStudies (and ENA). \n",
    "### What it does: \n",
    "1. submits a query -> list of hits\n",
    "2. filter hits for: organism, tissue (and more?)\n",
    "3. a1) If data at ENA: check for sex and age in table\n",
    "3. a2) If true: download fastq files\n",
    "3. b1) If count matrix available at BioStudies -> download count matrix directly (check for raw counts)\n",
    "### Learnings:\n",
    "### - mostly ENA got the data (fastq (i need to calc it myself somewhen ...))\n",
    "### - count matrix is attached to files \n",
    "### - probably more of this ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from scipy.io import mmread\n",
    "from utils.helper import get_negative_values, METADATA_COLS, reorder_columns_by_metadata_and_gene_counts, convert_gene_names_to_ensembl, clean_age\n",
    "from utils.plotting import violinplot_overall, scatter_plot, manhattanplot\n",
    "import requests\n",
    "from utils.biostudies import *\n",
    "from utils.ena import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_get_study=\"https://www.ebi.ac.uk/biostudies/api/v1/studies/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "###############################################################\n",
    "#NOTE QUERIES!!!! \n",
    "###############################################################\n",
    "# here i want to store some possible search queries, I produced the queries there and copied with inspect tool of the browser:  https://www.ebi.ac.uk/biostudies/ \n",
    "query_minimal = '%28RNA-seq+or+rnaseq%29+AND+%28human+or+%27homo+sapiens%27%29'   # ~3k results\n",
    "query_medium = '%28RNA-seq+or+rnaseq%29+AND+%28human+or+%27homo+sapiens%27%29+AND+%28blood+OR+%27whole+blood%27+OR+PBMC%29+AND+NOT+%27single+cell%27+AND+NOT+%27cord+blood%27' # 630 results\n",
    "query_long=\"%28rna-seq+OR+rnaseq%29+AND+%28human+OR+%22homo+sapiens%22%29+AND+%28blood+OR+%22whole+blood%22+OR+PBMC%29+AND+%28%22bulk%22%29+AND+NOT+%28sc+OR+%22single-cell%22%29+AND+NOT+DNA\"\n",
    "## pageSize 100 is max...\n",
    "\n",
    "#NOTE used query! \n",
    "query = query_medium\n",
    "\n",
    "current_page = 1\n",
    "url_get_all = f\"https://www.ebi.ac.uk/biostudies/api/v1/search?pageSize=100&page={str(current_page)}&query=\"\n",
    "\n",
    "##\n",
    "url = url_get_all + query\n",
    "print(url)\n",
    "data = get_biosample_query_response(url)\n",
    "hits = data.get(\"hits\", [])\n",
    "total_hits = data.get(\"totalHits\")\n",
    "\n",
    "print(f'{len(hits)} / {total_hits}')\n",
    "\n",
    "filtered_hits = [hit for hit in hits if \"GEO\" not in hit[\"accession\"]]\n",
    "## GEO Stuff will be handles by marc \n",
    "\n",
    "print(f'{len(filtered_hits)}')\n",
    "\n",
    "# Display the filtered results\n",
    "for hit in filtered_hits:\n",
    "    \n",
    "    response = requests.get(url_get_study + hit['accession'])\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        is_useful, useful_files = filter_study_characteristics(data)\n",
    "        print(f\"Useful: {is_useful}\")           \n",
    "        if not is_useful:\n",
    "            continue\n",
    "    \n",
    "        found_links = get_key_structure_for_string(data['section'], \"links\") # can be NoneType ... \n",
    "    \n",
    "        print(\"=\"*50)            \n",
    "        print(f\"Accession: {hit['accession']}\")\n",
    "        print(f\"Title: {hit['title']}\")\n",
    "        print(f\"Views: {hit['views']}\")\n",
    "        print(f\"Useful files: {useful_files} for {hit}\")\n",
    "        print(f\"Found links: {found_links}\")\n",
    "        print(\"=\"*50)            \n",
    "\n",
    "        if found_links:\n",
    "            for found_link in found_links:\n",
    "                link_block_handling(found_link)\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "    \n",
    "    if total_hits - len(hits) > 0:\n",
    "        current_page += 1\n",
    "        \n",
    "        #TODO next 100 pages ... when the first work fine :) \n",
    "        \n",
    "        \n",
    "    time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

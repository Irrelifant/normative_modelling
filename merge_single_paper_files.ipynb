{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is designed to merge the single papers together to assemble one bigger data-csv that we can at some point use for model training\n",
    "\n",
    "TODO: \n",
    "Investigate: \n",
    "https://www.nature.com/articles/s41598-023-41443-4?fromPaywallRec=false \n",
    "https://www.nature.com/articles/s41593-023-01514-1.pdf \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Notes: \n",
    "- To execute the notebook, you frist need to produce the .csv from the underlying papers\n",
    "- I try to convert and select for ENSG gene rows as we got  datasets from Flo with 60k entries which most probably will be me mayjority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from scipy.io import mmread\n",
    "from utils.plotting import manhattanplot, violinplot_overall, scatter_plot\n",
    "from utils.helper import keep_latest_ensamble_version, get_negative_values, METADATA_COLS, reorder_columns_by_metadata_and_gene_counts, convert_gene_names_to_ensembl, clean_age\n",
    "from utils.filepath import *\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wimmers 2023 (NOT INCLUDED)\n",
    "#NOTE This is 1 of 2 Datasets from this paper. \n",
    "#NOTE Also this datasets should be clarified with Flo first. ItÂ´s PBMC but not clear from whom ? (maybe GSE239799 ??? but also different)\n",
    "wimmers_2_df = pd.read_csv(f'{PATH_WIMMERS2023_COMBI}')\n",
    "print(wimmers_2_df.shape)\n",
    "PLATFORM_GEO_ID_wimmers_23 = \"GPL24676\"\n",
    "wimmers_2_df['PLATFORM_GEO_ID']=PLATFORM_GEO_ID_wimmers_23\n",
    "\n",
    "PLATFORM_DESCRIPTION_wimmers_23 = \"Illumina NovaSeq 6000 (Homo sapiens)\"\n",
    "wimmers_2_df['PLATFORM_DESCRIPTION']=PLATFORM_DESCRIPTION_wimmers_23\n",
    "\n",
    "METHOD_wimmers_23 = \"RNAseq\"\n",
    "wimmers_2_df['METHOD']=METHOD_wimmers_23\n",
    "\n",
    "#TODO in the data itself PBMC is mentioned but https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE239787 it is whole blood \n",
    "TYPE_wimmers_23 = \"blood\"\n",
    "wimmers_2_df['TYPE']=TYPE_wimmers_23\n",
    "\n",
    "desease_wimmers_23 = \"SARS-CoV-2 / healthy\"\n",
    "wimmers_2_df['desease']=desease_wimmers_23\n",
    "\n",
    "wimmers_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wimmers 2023 GEO239787\n",
    "#NOTE This is 2 of 2 Datasets from this paper. The GEO Is more useable as it contains what we need\n",
    "wimmers_GEO239787_df = pd.read_csv(PATH_WIMMER2023_GEO, index_col=0)\n",
    "\n",
    "\n",
    "wimmers_GEO239787_df = wimmers_GEO239787_df.rename(columns={\n",
    "    'ID':'subject_accession', \n",
    "  'geo_accession':'data_accession',\n",
    "    'characteristics_ch1.4':'age',\n",
    "    'characteristics_ch1.3':'gender',\n",
    "    'Status':'desease', \n",
    "  'contact_city':'origin',\n",
    "   'library_strategy':'METHOD', \n",
    "   'source_name_ch1':'TYPE',\n",
    "   'instrument_model':'PLATFORM_DESCRIPTION',\n",
    "   'platform_id':'PLATFORM_GEO_ID'\n",
    "})\n",
    "\n",
    "wimmers_GEO239787_df['study_accession']='GSE239787'\n",
    "wimmers_GEO239787_df['origin']='Contact City: Palo Alto'\n",
    "wimmers_GEO239787_df['age']=wimmers_GEO239787_df['age'].str.replace('age, months: ', '').astype(float)\n",
    "wimmers_GEO239787_df['age']=wimmers_GEO239787_df['age']/12\n",
    "\n",
    "wimmers_GEO239787_df_reduced = reorder_columns_by_metadata_and_gene_counts(wimmers_GEO239787_df)\n",
    "\n",
    "print(wimmers_GEO239787_df_reduced.shape)\n",
    "wimmers_GEO239787_df_reduced.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 Arunachalam, Wimmers\n",
    "#NOTE migh had some issues in the prep df file, but the GEO actually did a good job \n",
    "#NOTE I can probably add 4 more subjects but want to clarify with flo first\n",
    "aranachalam_2020_GSE152418_df = pd.read_csv(PATH_ARUNACHALAM2020_FINALDESTINATION, index_col=0)\n",
    "print(aranachalam_2020_GSE152418_df.shape)\n",
    "aranachalam_2020_GSE152418_df = aranachalam_2020_GSE152418_df.rename(columns={\n",
    "  'title':'subject_accession', \n",
    "  'geo_accession':'data_accession',\n",
    "  'Age':'age',\n",
    "  'characteristics_ch1.2':'gender',\n",
    "  'characteristics_ch1.3':'desease', \n",
    "  'contact_city':'origin',\n",
    "  'library_strategy':'METHOD', \n",
    "  'source_name_ch1':'TYPE',\n",
    "  'instrument_model':'PLATFORM_DESCRIPTION',\n",
    "  'platform_id':'PLATFORM_GEO_ID',\n",
    "})\n",
    "aranachalam_2020_GSE152418_df['study_accession'] = 'GSE152418'\n",
    "aranachalam_2020_GSE152418_df = reorder_columns_by_metadata_and_gene_counts(aranachalam_2020_GSE152418_df)\n",
    "print(aranachalam_2020_GSE152418_df.shape)\n",
    "aranachalam_2020_GSE152418_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021 Thair COVID \n",
    "# NOTE \n",
    "\n",
    "thair_2021_GSE152641_df = pd.read_csv(f\"{BASE_PATH}/2021_thair/thair_combi_covid.csv\", low_memory=False, index_col=0)\n",
    "thair_2021_GSE152641_df = thair_2021_GSE152641_df.loc[1:86, :] # there are 3 meta rows in the csv... \n",
    "print(thair_2021_GSE152641_df.shape)\n",
    "thair_2021_GSE152641_df = thair_2021_GSE152641_df.rename(columns={\n",
    "  'title':'subject_accession', \n",
    "    'geo_accession':'data_accession',\n",
    "    'characteristics_ch1.3':'age',\n",
    "    'characteristics_ch1.4':'gender',\n",
    "    'characteristics_ch1':'desease',\n",
    "  'contact_city':'origin',\n",
    "  'library_strategy':'METHOD',\n",
    "  'characteristics_ch1.2':'TYPE',\n",
    "  'instrument_model':'PLATFORM_DESCRIPTION',\n",
    "  'platform_id':'PLATFORM_GEO_ID',\n",
    "})\n",
    "thair_2021_GSE152641_df['study_accession'] ='GSE152641'\n",
    "thair_2021_GSE152641_ordered_df = reorder_columns_by_metadata_and_gene_counts(thair_2021_GSE152641_df)\n",
    "print(thair_2021_GSE152641_ordered_df.shape)\n",
    "\n",
    "columns_to_cast = thair_2021_GSE152641_ordered_df.columns[11:]\n",
    "thair_2021_GSE152641_ordered_df[columns_to_cast] = thair_2021_GSE152641_ordered_df[columns_to_cast].astype(float)\n",
    "\n",
    "\n",
    "thair_2021_GSE152641_ordered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021 Aranachalam VACCINE\n",
    "#NOTE Had to convert Gene names to ENSEMBL which sometimes results in a not found version -> Flo how to handle \n",
    "#NOTE Vaccine study, i just took the Baseline (blood before the vaccine was given)\n",
    "\n",
    "import copy\n",
    "\n",
    "aranachalam_2021_GSE169159_df = pd.read_csv(f'{BASE_PATH}/2021_arunachalam/2021_aranachalam_vaccine_combi_df_baseline.csv')\n",
    "print(aranachalam_2021_GSE169159_df.shape)\n",
    "aranachalam_2021_GSE169159_df = aranachalam_2021_GSE169159_df.rename(columns={\n",
    "  'title':'subject_accession', \n",
    "  'geo_accession':'data_accession',\n",
    "  'age':'age',\n",
    "    'sex':'gender',\n",
    "  'contact_city':'origin',\n",
    "  'library_strategy':'METHOD',\n",
    "  'source_name_ch1':'TYPE',\n",
    "  'instrument_model':'PLATFORM_DESCRIPTION',\n",
    "  'platform_id':'PLATFORM_GEO_ID',\n",
    "})\n",
    "aranachalam_2021_GSE169159_df['desease']='Healthy'\n",
    "aranachalam_2021_GSE169159_df['study_accession']='GSE169159'\n",
    "\n",
    "## This is weird as the overwrite of a subset of columns of a dataframe seems not to work. I tried stuff in different patterns here\n",
    "print(f\"First gene: {aranachalam_2021_GSE169159_df.columns.get_loc('FGR')}\")\n",
    "gene_names_to_convert = aranachalam_2021_GSE169159_df.iloc[:, 38:-2].copy().columns\n",
    "aranachalam_2021_GSE169159_ordered_df = reorder_columns_by_metadata_and_gene_counts(aranachalam_2021_GSE169159_df, \n",
    "                                                                                    metadata_cols=METADATA_COLS,\n",
    "                                                                                    gene_columns=gene_names_to_convert)\n",
    "print(f\"First gene: {aranachalam_2021_GSE169159_ordered_df.columns.get_loc('FGR')}\")\n",
    "converted_gene_names = convert_gene_names_to_ensembl(aranachalam_2021_GSE169159_ordered_df.iloc[:, 11:].copy().columns)\n",
    "\n",
    "# Now i want to overwrite every column of the dataset (also i dont need to use loc or iloc)\n",
    "all_dataset_new_columns = METADATA_COLS + converted_gene_names\n",
    "aranachalam_2021_GSE169159_ordered_df.columns = all_dataset_new_columns\n",
    "\n",
    "print(aranachalam_2021_GSE169159_ordered_df.columns[60])\n",
    "print(converted_gene_names[49]) # as i need to add the meta cols ... \n",
    "\n",
    "print(aranachalam_2021_GSE169159_ordered_df.shape)\n",
    "aranachalam_2021_GSE169159_ordered_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023 feargal\n",
    "# '/work/transcriptomics_norm_model/2023_feargal/2023_feargal_combi_df.csv'\n",
    "feargal_2023_GSE199750_df_init = pd.read_csv('/work/transcriptomics_norm_model/2023_feargal/2023_feargal_combi_df.csv')\n",
    "print(feargal_2023_GSE199750_df_init.shape)\n",
    "# HERE IS A BUG, the data got age and gender cols confused in some rows... \n",
    "feargal_2023_GSE199750_df_init.loc[:31, 'characteristics_ch1.2'] = feargal_2023_GSE199750_df_init.loc[:31, 'characteristics_ch1.3']\n",
    "feargal_2023_GSE199750_df_init.loc[:31, 'characteristics_ch1.3'] = feargal_2023_GSE199750_df_init.loc[:31, 'characteristics_ch1.4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feargal_2023_GSE199750_df_init['characteristics_ch1.3'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feargal_2023_GSE199750_df = feargal_2023_GSE199750_df_init.rename(columns={\n",
    "        'characteristics_ch1':'subject_accession', \n",
    "           'geo_accession':'data_accession',\n",
    "           'characteristics_ch1.2':'age',\n",
    "          'characteristics_ch1.3':'gender',\n",
    "          'contact_city':'origin',\n",
    "           'library_strategy':'METHOD',\n",
    "           'source_name_ch1':'TYPE',\n",
    "          'instrument_model':'PLATFORM_DESCRIPTION',\n",
    "          'platform_id':'PLATFORM_GEO_ID',\n",
    "})\n",
    "feargal_2023_GSE199750_df['desease']='Healthy'\n",
    "feargal_2023_GSE199750_df['study_accession']='GSE199750'\n",
    "feargal_2023_GSE199750_reordered_df = reorder_columns_by_metadata_and_gene_counts(feargal_2023_GSE199750_df)\n",
    "print(feargal_2023_GSE199750_reordered_df.shape)\n",
    "feargal_2023_GSE199750_reordered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOARES-SCHANINSKI\n",
    "#NOTE CHIKV virus patients and ~20 healthy controls\n",
    "\n",
    "soares_df = pd.read_csv('/work/transcriptomics_norm_model/2019_soares/2019_soares_combi_df.csv')\n",
    "print(soares_df.shape)\n",
    "soares_df = soares_df.rename(columns={\n",
    "                'BioSample':'subject_accession', \n",
    "                'Run':'data_accession',\n",
    "                'Age':'age',\n",
    "                'sex':'gender',\n",
    "                'Center Name':'origin',\n",
    "                'Assay Type':'METHOD',\n",
    "                'tissue':'TYPE',\n",
    "                'Instrument':'PLATFORM_DESCRIPTION',\n",
    "                'disease': 'desease'\n",
    "})\n",
    "soares_df['study_accession']='BioProject'\n",
    "soares_df['PLATFORM_GEO_ID']='-'\n",
    "soares_df = reorder_columns_by_metadata_and_gene_counts(soares_df)\n",
    "print(soares_df.shape)\n",
    "soares_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O'Connell\n",
    "#NOTE Different deseased patients\n",
    "\n",
    "oconnell_df = pd.read_csv(f'{OCONNELL2023_COMBI}')\n",
    "print(oconnell_df.shape)\n",
    "oconnell_df = oconnell_df.rename(columns={\n",
    "                 'index':'subject_accession', \n",
    "                 'BioSample':'study_accession',\n",
    "                 'Run':'data_accession',\n",
    "                 'AGE':'age',\n",
    "                 'sex':'gender',\n",
    "                 'Center Name':'origin',\n",
    "                 'Assay Type':'METHOD',\n",
    "                 'tissue':'TYPE',\n",
    "                 'Instrument':'PLATFORM_DESCRIPTION',\n",
    "                 'disease': 'desease',\n",
    "})\n",
    "\n",
    "oconnell_df['PLATFORM_GEO_ID']='GPL24676'\n",
    "oconnell_df = reorder_columns_by_metadata_and_gene_counts(oconnell_df)\n",
    "print(oconnell_df.shape)\n",
    "oconnell_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dr. Susanne Edelmann\n",
    "# NOTE: from Psychiatry , found its GEO Entries: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE228702 \n",
    "edelmann_df = pd.read_csv(EDLMANN2023_COMBI)\n",
    "print(edelmann_df.shape)\n",
    "edelmann_df = edelmann_df.rename(columns={\n",
    "                   'seq_name':'subject_accession', \n",
    "                    'AGE':'age',\n",
    "                    'SEX':'gender',\n",
    "                    'SAD': 'desease',\n",
    "})\n",
    "edelmann_df['PLATFORM_DESCRIPTION'] = 'Illumina NovaSeq 6000'\n",
    "edelmann_df['data_accession']  = 'SAMN34035152'\n",
    "edelmann_df['study_accession'] = 'GSE228702'\n",
    "edelmann_df['TYPE'] = 'whole blood'\n",
    "edelmann_df['METHOD'] = 'RNAseq'\n",
    "edelmann_df['origin'] = 'Department of Psychiatry and Psychotherapy, University Hospital of Tuebingen'\n",
    "edelmann_df['PLATFORM_GEO_ID']='GPL24676'\n",
    "edelmann_df = reorder_columns_by_metadata_and_gene_counts(edelmann_df)\n",
    "\n",
    "edelmann_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE PPMI, i might move this to a different notebook tho... \n",
    "from utils.filepath import *\n",
    "\n",
    "ppmi_ir3_baseline_df = pd.read_csv(PPMI_IR3_COMBI_BL)\n",
    "print(ppmi_ir3_baseline_df.shape)\n",
    "ppmi_ir3_baseline_df.head()\n",
    "\n",
    "ppmi_ir3_baseline_df = ppmi_ir3_baseline_df.rename(columns={\n",
    "                      'PATNO':'subject_accession', \n",
    "                      'Sample':'data_accession',\n",
    "                      'ENROLL_AGE':'age',\n",
    "                      'GENDER':'gender',\n",
    "                      'DIAGNOSIS': 'desease',\n",
    "})\n",
    "ppmi_ir3_baseline_df['PLATFORM_DESCRIPTION'] = 'Illumina NovaSeq 6000'\n",
    "ppmi_ir3_baseline_df['PLATFORM_GEO_ID']='GPL24676'\n",
    "ppmi_ir3_baseline_df['study_accession'] = 'IR3_p1+p2'\n",
    "ppmi_ir3_baseline_df['METHOD'] = 'RNAseq'\n",
    "ppmi_ir3_baseline_df['TYPE'] = 'whole blood'\n",
    "ppmi_ir3_baseline_df['origin'] = 'PPMI'\n",
    "ppmi_ir3_baseline_df = reorder_columns_by_metadata_and_gene_counts(ppmi_ir3_baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: This cell is there to take the latest version of the gene count, without this cell we would have douplicate column names, what makes concat impossible\n",
    "\n",
    "## As PPMI uses version identifiesers (ENSG00000243485.5 the .5 part...) we need to trim these, when there are duplicates afterwards, i take the latest version\n",
    "ppmi_ir3_baseline_w_duplicates_df = copy.copy(ppmi_ir3_baseline_df)\n",
    "ppmi_ir3_baseline_w_duplicates_df.columns = [col.split('.')[0] for col in ppmi_ir3_baseline_w_duplicates_df.columns]\n",
    "duplicates = ppmi_ir3_baseline_w_duplicates_df.columns[ppmi_ir3_baseline_w_duplicates_df.columns.duplicated()]\n",
    "print(duplicates)    # expected 0 duplicates as version nr are still there\n",
    "\n",
    "ppmi_ir3_baseline_wo_duplicates_df = keep_latest_ensamble_version(ppmi_ir3_baseline_df, duplicates=duplicates)\n",
    "ppmi_ir3_baseline_wo_duplicates_df.columns = [col.split('.')[0] for col in ppmi_ir3_baseline_wo_duplicates_df.columns]\n",
    "print(ppmi_ir3_baseline_wo_duplicates_df.columns[ppmi_ir3_baseline_wo_duplicates_df.columns.duplicated()])\n",
    "ppmi_ir3_baseline_wo_duplicates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppmi_ir3_baseline_wo_duplicates_df.groupby('desease').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatinated_df = pd.concat([aranachalam_2020_GSE152418_df, \n",
    "                             wimmers_GEO239787_df_reduced, \n",
    "                             thair_2021_GSE152641_ordered_df, \n",
    "                             aranachalam_2021_GSE169159_ordered_df, \n",
    "                             feargal_2023_GSE199750_reordered_df,\n",
    "                             oconnell_df,\n",
    "                             edelmann_df,\n",
    "                             soares_df,\n",
    "                             ppmi_ir3_baseline_wo_duplicates_df\n",
    "                             ])\n",
    "# missing is wimmers_2 as i need clarification there\n",
    "#                             ppmi_ir3_baseline_wo_duplicates_df,\n",
    "\n",
    "concatinated_df = concatinated_df.reset_index(drop=True)\n",
    "print(concatinated_df.shape)\n",
    "concatinated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinated_df.to_csv(f'{BASE_PATH}/combi_df_concat_10.10.24.csv')\n",
    "#concatinated_df = pd.read_csv(f'{BASE_PATH}/combi_df_concat_10.10.24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE proof if any dta col is not of float type\n",
    "#Problem1 cant convert 'IMX_sample00001'\n",
    "columns_to_cast = concatinated_df.columns[11:]\n",
    "for column in columns_to_cast:\n",
    "    try:\n",
    "        concatinated_df[column] = pd.to_numeric(concatinated_df[column], errors='raise')  # Will throw an error if there's an issue\n",
    "    except ValueError:\n",
    "        print(f\"Column '{column}' contains non-numeric values.\")\n",
    "### Solution: I concat thairs non-ordered df....\n",
    "\n",
    "#concatinated_df.drop_na(axis=1, how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unify the different valuee "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'gender: F': 'Female',\n",
    "    'gender: M': 'Male',\n",
    "    'Sex: Male': 'Male',\n",
    "    'Sex: Female': 'Female',\n",
    "    'female': 'Female',\n",
    "    'male': 'Male',\n",
    "}\n",
    "concatinated_df['gender'] = concatinated_df['gender'].replace(mapping)\n",
    "concatinated_df['gender'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the function and convert column to float\n",
    "concatinated_df['age'] = concatinated_df['age'].apply(clean_age).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Oconnell study has several deseases in the field separated by ','\n",
    "mapping = {\n",
    "    'disease state: COVID-19': 'Sars-CoV-2',\n",
    "    'disease: COVID19': 'Sars-CoV-2',\n",
    "    'acute': 'Sars-CoV-2',\n",
    "    'acute-omicron': 'Sars-CoV-2',\n",
    "    'disease state: Healthy': 'Healthy',\n",
    "    'healthy': 'Healthy',\n",
    "    'disease: Healthy control': 'Healthy',\n",
    "    'Healthy': 'Healthy',\n",
    "    'Control': 'Healthy',\n",
    "}\n",
    "concatinated_df['desease'] = concatinated_df['desease'].replace(mapping)\n",
    "concatinated_df['desease'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for duplicated subjects. Here just the same subj ID is most likely not sufficient (check those \"draws and so on \")\n",
    "print(len(concatinated_df['subject_accession'].unique()))\n",
    "concatinated_df_per_subject = concatinated_df.drop_duplicates(subset=['subject_accession'])\n",
    "concatinated_df_per_subject = concatinated_df_per_subject[~concatinated_df_per_subject['subject_accession'].str.endswith('Draw-2', na=False)]\n",
    "print(concatinated_df_per_subject.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinated_df_per_subject.to_csv(f'{BASE_PATH}/concatinated_df_per_subject_11.10.24.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

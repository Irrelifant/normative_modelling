{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immport_prefix=\"/var/datasets/ImmPort/immune_RNAseq/ALLSTUDIES/ALLSTUDIES-DR49.2_Tab/Tab/\"\n",
    "\n",
    "\n",
    "print(\"WORKSPACE\")\n",
    "print(\"============================================================\")\n",
    "workspace = pd.read_table(f\"{immport_prefix}/workspace.txt\",sep=\"\\t\")\n",
    "print(workspace.columns)\n",
    "print(workspace.shape)\n",
    "# study.head()\n",
    "\n",
    "\n",
    "print(\"STUDY\")\n",
    "print(\"============================================================\")\n",
    "study = pd.read_table(f\"{immport_prefix}/study.txt\",sep=\"\\t\")\n",
    "print(study.columns)\n",
    "print(study.shape)\n",
    "# study.head()\n",
    "\n",
    "print(\"\")\n",
    "print(\"ARM_OR_COHORT\")\n",
    "print(\"============================================================\")\n",
    "arm_or_cohort = pd.read_table(f\"{immport_prefix}/arm_or_cohort.txt\",sep=\"\\t\")\n",
    "print(arm_or_cohort.columns)\n",
    "print(arm_or_cohort.shape)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ARM_2_SUBJECT\")\n",
    "print(\"============================================================\")\n",
    "arm_2_subject = pd.read_table(f\"{immport_prefix}/arm_2_subject.txt\",sep=\"\\t\")\n",
    "print(arm_2_subject.columns)\n",
    "print(arm_2_subject.shape)\n",
    "\n",
    "# arm_2_subject.head()\n",
    "\n",
    "print(\"\")\n",
    "print(\"BIOSAMPLE\")\n",
    "print(\"============================================================\")\n",
    "biosample = pd.read_table(f\"{immport_prefix}/biosample.txt\",sep=\"\\t\")\n",
    "print(biosample.columns)\n",
    "print(biosample.shape)\n",
    "\n",
    "print(\"============================================================\")\n",
    "lab_test_panel = pd.read_table(f\"{immport_prefix}/lab_test_panel.txt\",sep=\"\\t\")\n",
    "print(lab_test_panel.columns)\n",
    "print(lab_test_panel.shape)\n",
    "\n",
    "print(\"\")\n",
    "print(\"LAB_TEST\")\n",
    "print(\"============================================================\")\n",
    "lab_test = pd.read_table(f\"{immport_prefix}/lab_test.txt\",sep=\"\\t\")\n",
    "print(lab_test.columns)\n",
    "print(lab_test.shape)\n",
    "\n",
    "print(\"\")\n",
    "print(\"SUBJECT\")\n",
    "print(\"============================================================\")\n",
    "subject = pd.read_table(f\"{immport_prefix}/subject.txt\", sep=\"\\t\") \n",
    "print(subject.shape)\n",
    "\n",
    "print(\"ASSESSMENT_PANEL\")\n",
    "print(\"============================================================\")\n",
    "assessment_panel = pd.read_table(f\"{immport_prefix}/assessment_panel.txt\",sep=\"\\t\")\n",
    "print(assessment_panel.columns)\n",
    "print(assessment_panel.shape)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ASSESSMENT_COMPONENT\")\n",
    "print(\"============================================================\")\n",
    "assessment_component = pd.read_table(f\"{immport_prefix}/assessment_component.txt\",sep=\"\\t\")\n",
    "print(assessment_component.columns)\n",
    "print(assessment_component.shape)\n",
    "workspace.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper methods\n",
    "\n",
    "def lab_test_panels_by_study(study_accession,lab_tests):\n",
    "    study_lab_tests = lab_tests[lab_tests['STUDY_ACCESSION']==study_accession]\n",
    "    study_panels = study_lab_tests[['PANEL_NAME','LAB_TEST_NAME']]\n",
    "    study_panels = study_panels.groupby(['PANEL_NAME','LAB_TEST_NAME']).size().reset_index(name=\"COUNTS\")\n",
    "    return study_panels\n",
    "def assessment_panels_by_study(study_accession,assessments):\n",
    "    study_assessments = assessments[assessments['STUDY_ACCESSION']==study_accession]\n",
    "    study_panels = study_assessments[['PANEL_NAME','COMPONENT_NAME']]\n",
    "    study_panels = study_panels.groupby(['PANEL_NAME','COMPONENT_NAME']).size().reset_index(name=\"COUNTS\")\n",
    "    return study_panels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many Labtests\n",
    "print(f'Labtests amount: {lab_test.drop_duplicates().shape}')\n",
    "print(f'Labtest panels amount: {lab_test_panel.drop_duplicates().shape}')\n",
    "\n",
    "## How many Subjects\n",
    "subject = subject[subject['SPECIES']=='Homo sapiens']\n",
    "print(f'Subject amount: {subject.drop_duplicates().shape}')\n",
    "subject_with_gender = subject[subject['GENDER'].isin(['Male' ,'Female'])].drop_duplicates()\n",
    "print(f'Subjects male/female amount: {subject_with_gender.shape}')\n",
    "\n",
    "## How many Studies\n",
    "print(f'Studies amount: {study.drop_duplicates().shape}')\n",
    "\n",
    "## Labtests: \"Biomarkers\", welche "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study[study['STUDY_ACCESSION']=='SDY67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study['GENDER_INCLUDED'].unique()\n",
    "arm_2_subject_valid = arm_2_subject[arm_2_subject['SUBJECT_ACCESSION'].isin(subject_with_gender['SUBJECT_ACCESSION'])]\n",
    " \n",
    "duplicates = arm_2_subject_valid[arm_2_subject_valid.duplicated('SUBJECT_ACCESSION', keep='first')] \n",
    "## keep says if we want to see every enry just once or all duplicates of it\n",
    "print(f'Arm 2 Subject duplicates: {duplicates.shape}')\n",
    "arm_2_subject_valid['AGE_UNIT'].unique() # 'Years', 'Not Specified', 'Weeks', 'Months', 'Days', 'Hours' \n",
    "### here we need to see... babys may have a month or days unit ... hours is strange for homo sapiens... \n",
    "arm_2_subject_valid = arm_2_subject_valid.dropna(subset=['MAX_SUBJECT_AGE_IN_YEARS', 'MIN_SUBJECT_AGE_IN_YEARS'])\n",
    "### As we have different age events we should despite track the duplicated subjects!\n",
    "print(f'Subjects valid aged male/female {arm_2_subject_valid.drop_duplicates('SUBJECT_ACCESSION').shape}')\n",
    "mismatch_age = arm_2_subject_valid[arm_2_subject_valid['MAX_SUBJECT_AGE_IN_YEARS'] != arm_2_subject_valid['MIN_SUBJECT_AGE_IN_YEARS']]\n",
    "print(f'Subjects with MIN / MAX age mismatch {mismatch_age.drop_duplicates('SUBJECT_ACCESSION').shape}')\n",
    "\n",
    "arm_2_subject_valid['AGE_EVENT'].unique() # 'Age at enrollment', 'Other', 'Not Specified', 'Age at initial vaccine administration', 'Age at Study Day 0', 'Age at infection', 'Age at initial treatment'\n",
    "\n",
    "subject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_2_subject_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_w_age = pd.merge(arm_2_subject_valid, subject, on='SUBJECT_ACCESSION', how='left') ### I merge into arm_2_subject_valid as we have duplicated rows here that i probably want to keep whilst in the other its unique\n",
    "subject_w_age.to_csv('tables/subject_w_age.csv')\n",
    "subject_w_age.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_2_subject['AGE_EVENT'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LAB TEST PANEL INSIGHTS\n",
    "\n",
    "lab_test_panel = lab_test_panel.rename(columns={'NAME_REPORTED': 'PANEL_NAME'})\n",
    "lab_test = lab_test.rename(columns={'NAME_REPORTED': 'LAB_TEST_NAME'})\n",
    "lab_tests = pd.merge(lab_test_panel,lab_test,\n",
    "                    left_on='LAB_TEST_PANEL_ACCESSION',right_on='LAB_TEST_PANEL_ACCESSION') \n",
    "lab_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_tests = pd.merge(lab_test_panel,lab_test,\n",
    "                    left_on='LAB_TEST_PANEL_ACCESSION',right_on='LAB_TEST_PANEL_ACCESSION')\n",
    "print(lab_tests.shape)\n",
    "lab_tests.to_csv('tables/lab_tests.csv')\n",
    "lab_tests_backup = lab_tests.copy(deep=True)\n",
    "lab_tests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper methods\n",
    "def lab_test_panels(lab_tests):\n",
    "    study_panels = lab_tests[['PANEL_NAME','LAB_TEST_NAME']]\n",
    "    study_panels = study_panels.groupby(['PANEL_NAME','LAB_TEST_NAME']).size().reset_index(name=\"COUNTS\")\n",
    "    return study_panels\n",
    "def lab_test_panels_prefered_names(lab_tests):\n",
    "    study_panels = lab_tests[['NAME_PREFERRED_x','NAME_PREFERRED_y']]\n",
    "    study_panels = study_panels.groupby(['NAME_PREFERRED_x','NAME_PREFERRED_y']).size().reset_index(name=\"COUNTS\")\n",
    "    return study_panels\n",
    "\n",
    "lab_tests_PANEL_NAME = lab_test_panels(lab_tests)\n",
    "lab_tests_NAME_PREFERRED = lab_test_panels_prefered_names(lab_tests)\n",
    "PANEL_NAMEs_unique = lab_tests_PANEL_NAME['PANEL_NAME'].unique()\n",
    "LAB_TESTS_unique = lab_tests_PANEL_NAME['LAB_TEST_NAME'].unique()\n",
    "NAME_PREFERRED_x_unique = lab_tests_NAME_PREFERRED['NAME_PREFERRED_x'].unique()\n",
    "NAME_PREFERRED_y_unique = lab_tests_NAME_PREFERRED['NAME_PREFERRED_y'].unique()\n",
    "\n",
    "\n",
    "print('PANEL_NAMEs '  + str(len(PANEL_NAMEs_unique)))\n",
    "print('LAB_TESTS '  + str(len(LAB_TESTS_unique)))\n",
    "print('LAB_TEST counts: ' + str(sum(lab_tests_PANEL_NAME['COUNTS'])))\n",
    "print('PANEL_NAMEs preferred names '  + str(len(NAME_PREFERRED_x_unique)))\n",
    "print('LAB_TESTS preferred names '  + str(len(NAME_PREFERRED_y_unique)))\n",
    "print('LAB_TEST preferred counts: ' + str(sum(lab_tests_NAME_PREFERRED['COUNTS'])))\n",
    "\n",
    "\n",
    "lab_tests_PANEL_NAME.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NA NAME_PREFERRED_x: ' + str(lab_tests['NAME_PREFERRED_x'].isna().sum()))\n",
    "print('NA NAME_PREFERRED_y: ' + str(lab_tests['NAME_PREFERRED_y'].isna().sum()))\n",
    "print('NA PANEL_NAME: ' + str(lab_tests['PANEL_NAME'].isna().sum()))\n",
    "print('NA LAB_TEST_NAME: ' + str(lab_tests['LAB_TEST_NAME'].isna().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LIST FOR BINNING THE INDIVIDUAL STUDY TYPES!\n",
    "#grouped = lab_tests_PANEL_NAME.groupby('PANEL_NAME')['LAB_TEST_NAME'].apply(list).reset_index()\n",
    "#for index, row in grouped.iterrows():\n",
    "\"\"\"  group = row['PANEL_NAME']\n",
    "    pref_name = lab_tests[lab_tests['PANEL_NAME'] == group]['NAME_PREFERRED_x'].values\n",
    "    if len(pref_name) > 0:\n",
    "        pref_name = pref_name[0]\n",
    "    else: \n",
    "        pref_name = ''\n",
    "        \n",
    "    items = row['LAB_TEST_NAME'][0]\n",
    "    \n",
    "    pref_item = {}\n",
    "    for i, x in enumerate(row['LAB_TEST_NAME']):\n",
    "        y = lab_tests[lab_tests['LAB_TEST_NAME'] == row['LAB_TEST_NAME'][i]]['NAME_PREFERRED_y'].values\n",
    "        if len(y) > 0:\n",
    "            pref_item[i] = y[0]\n",
    "        else:\n",
    "            pref_item[i] = ''\n",
    "    \n",
    "    print(f\"\\n{group} ({pref_name})\")\n",
    "    [print('\\t' + str(x) + f' ({pref_item[i]})') for i, x in enumerate(row['LAB_TEST_NAME'])] \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### biomarkers\n",
    "biomarker_PANEL_NAMEs = [\n",
    "    'Blood Flow Cytometry: ',\n",
    "    'Protein or Enzyme Type Measurement: ',\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next step: Get all Study accessions related to the biomarker and cell type bins\n",
    "### Then: Get the subject\n",
    "biomarker_PANEL_NAMEs_trimmed = [x[:-2] for x in biomarker_PANEL_NAMEs]\n",
    "biomarker_all_tests = lab_tests[lab_tests['PANEL_NAME'].isin(biomarker_PANEL_NAMEs_trimmed)]\n",
    "biomarker_all_tests.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomarker_all_studies_array = biomarker_all_tests['STUDY_ACCESSION'].unique()\n",
    "biomarker_all_studies = study[study['STUDY_ACCESSION'].isin(biomarker_all_studies_array)]\n",
    "biomarker_all_studies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_w_age.columns ## ALLDATA subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_or_cohort.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I take subject_w_age as I want the duplicates in this position, just need to remember to remove them for the plots\n",
    "study_arm_subject = pd.merge(subject_w_age, arm_or_cohort, left_on='ARM_ACCESSION',right_on='ARM_ACCESSION')\n",
    "study_arm_subject.to_csv('tables/study_arm_subject.csv')\n",
    "### I expect to have the same duplicates number of duplicates as before as we kepts the different time event data: \n",
    "duplicates = study_arm_subject[study_arm_subject.duplicated('SUBJECT_ACCESSION', keep='first')] \n",
    "study_arm_subject.columns # Here I get GENDER and AGE data for subjects (SUBJECT_ACCESSION).\n",
    "# Also I get related studies (STUDY_ACCESSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Here I want to testwise prinst status for biomarker samples\n",
    "### SUBJECT extraction\n",
    "biomarker_study_arm_subject = study_arm_subject[study_arm_subject['STUDY_ACCESSION'].isin(biomarker_all_studies['STUDY_ACCESSION'])]\n",
    "biomarker_study_arm_subject_no_duplicated = biomarker_study_arm_subject.drop_duplicates('SUBJECT_ACCESSION')\n",
    "print(f'Amount of Subjects: {biomarker_study_arm_subject.shape}')\n",
    "print(f'Amount of Subjects no duplicates: {biomarker_study_arm_subject_no_duplicated.shape}')\n",
    "biomarker_study_arm_subject['AGE_EVENT'].unique() ## 'Age at initial treatment', 'Other', 'Age at enrollment', 'Age at Study Day 0'\n",
    "## here aprently the age events are several, problbly for the individual studies... \n",
    "biomarker_study_arm_subject_no_duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OVERALL\n",
    "#sns.violinplot(x='GENDER', y='MAX_SUBJECT_AGE_IN_YEARS', hue='GENDER', data=biomarker_study_arm_subject_no_duplicated[['GENDER', 'MAX_SUBJECT_AGE_IN_YEARS']], split=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "### Letztes meeting mit florian: only bulk Transcriptomics to start with! \n",
    "############################################################################\n",
    "print(\"\")\n",
    "### Aparently this is the Gene expression data... will dig ito this a bit... \n",
    "print(\"EXPSAMPLE_PLUBLIC_REPOSITORY\")\n",
    "print(\"============================================================\")\n",
    "gene_expression = pd.read_table(f\"{immport_prefix}/expsample_public_repository.txt\",sep=\"\\t\")\n",
    "print(gene_expression.columns)\n",
    "print(gene_expression.shape)\n",
    "\n",
    "print(\"EXPSAMPLE\")\n",
    "print(\"============================================================\")\n",
    "expsample = pd.read_table(f\"{immport_prefix}/expsample.txt\",sep=\"\\t\")\n",
    "print(expsample.columns)\n",
    "print(expsample.shape)\n",
    "\n",
    "print(\"EXPERIMENT\")\n",
    "print(\"============================================================\")\n",
    "experiment = pd.read_table(f\"{immport_prefix}/experiment.txt\",sep=\"\\t\")\n",
    "print(experiment.columns)\n",
    "print(experiment.shape)\n",
    "\n",
    "print(\"BIOSAMPLE\")\n",
    "print(\"============================================================\")\n",
    "biosample = pd.read_table(f\"{immport_prefix}/biosample.txt\",sep=\"\\t\")\n",
    "print(biosample.columns)\n",
    "print(biosample.shape)\n",
    "\n",
    "\n",
    "print(\"EXPSAMPLE_2_BIOSAMPLE\")\n",
    "print(\"============================================================\")\n",
    "expsample_2_biosample = pd.read_table(f\"{immport_prefix}/expsample_2_biosample.txt\",sep=\"\\t\")\n",
    "print(expsample_2_biosample.columns)\n",
    "print(expsample_2_biosample.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO measurement techniques die sinn machen in list ordnen \n",
    "####### -> damit DB reduzieren und dann NAME und DESCRIPTION nehmen um weiter zu arbeiten\n",
    "####### -> ergebniss evtl nochmal kurz mit flo absprechen wenn Zeit...\n",
    "experiment['MEASUREMENT_TECHNIQUE'].unique()\n",
    "valid_measurement_techiques = [\n",
    "    'SNP microarray',\n",
    "    'Transcription profiling by array',\n",
    "    'Other',\n",
    "    'Sequencing',\n",
    "    'Flow Cytometry',\n",
    "    'Q-PCR',\n",
    "    'PCR',\n",
    "    'CyTOF',\n",
    "    'Liquid Chromatography',\n",
    "    'Nanostring',\n",
    "    'microRNA profiling assay',\n",
    "    'Array',\n",
    "    'Transcription profiling assay',\n",
    "    'Real time polymerase chain reaction assay',\n",
    "    'LC_MS',\n",
    "    'in situ Hybridization', \n",
    "    'DNA microarray'\n",
    "                               ]\n",
    "\n",
    "\n",
    "## aparently DNA microarray can also be used for RNA \n",
    "## Liquid Chromatography -> es gibt wohl ne LC technik die RNAseq kann\n",
    "\n",
    "\n",
    "## Flow Cytometry -> eher protein aber lass ich mal drin... \n",
    "## Immunoblot = Westernblot -> Proteine (Northern Blot wäre RNA)\n",
    "## PCR -> reverse transcription: \n",
    "## Real-time PCR, on the other hand, is a more targeted approach to gene expression analysis\n",
    "## Cytometric Bead Array Assay , SOMAscan assay -> proteins\n",
    "## Olink assay, Multiplex Bead Array Assay -> protein biomarkers\n",
    "\n",
    "## EMSA -> Protein - RNA interaction\n",
    "\n",
    "## Whole Genome Sequencing , DNA microarray -> DNA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject['SPECIES'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_transcriptomes = experiment[experiment['MEASUREMENT_TECHNIQUE'].isin(valid_measurement_techiques)]\n",
    "### ALSO i need to filter for homo sapiens ... \n",
    "workspace_ids_homo_sapiens = subject[subject['SPECIES'] == 'Homo sapiens']['WORKSPACE_ID'].unique()\n",
    "experiment_transcriptomes_human = experiment_transcriptomes[experiment_transcriptomes['WORKSPACE_ID'].isin(workspace_ids_homo_sapiens)]\n",
    "experiment_transcriptomes_human.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hier wieder ne List aus der ich händisch raus sortien will welche methoden nicht passen\n",
    "################################\n",
    "### Ab hier mess ich BULK \n",
    "## kein CyTOF, Other -> ich mach mal nur microarray und sequencing und erweitere des stück für stück ... \n",
    "\n",
    "experiment_transcriptomes_sorted = experiment_transcriptomes_human.sort_values(by='MEASUREMENT_TECHNIQUE')\n",
    "for name, group in experiment_transcriptomes_sorted.groupby('MEASUREMENT_TECHNIQUE'):\n",
    "    print(f\"{name}\")\n",
    "    for _, row in group.iterrows():\n",
    "        print(f\"\\t {row['NAME']} ({row['DESCRIPTION']})\")\n",
    "    print() \n",
    "    \n",
    "    \n",
    "sorted_out_measurements = [\n",
    "    'CyTOF',\n",
    "    'Other',\n",
    "    '',\n",
    "    '',\n",
    "]\n",
    "\n",
    "sorted_out_names = [\n",
    "    'VT2020',\n",
    "    'Bacterial re-isolation (nan)',\n",
    "    '',\n",
    "    '',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Raus nehmen :     'SNP microarray', 'DNA microarray', \n",
    "include_measurements = [\n",
    "    'Transcription profiling by array',\n",
    "    'Sequencing',\n",
    "    'Array',\n",
    "]\n",
    "experiment_transcriptomes_sorted_ma_seq = experiment_transcriptomes_sorted[experiment_transcriptomes_sorted['MEASUREMENT_TECHNIQUE'].isin(include_measurements)]\n",
    "experiment_transcriptomes_sorted_ma_seq['MEASUREMENT_TECHNIQUE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_transcriptomes_sorted_ma_seq_experiments = experiment_transcriptomes_sorted_ma_seq['EXPERIMENT_ACCESSION'].unique()\n",
    "studies_transcriptomes_sorted_ma_seq_experiments = experiment_transcriptomes_sorted_ma_seq['STUDY_ACCESSION'].unique()\n",
    "\n",
    "print('BULK RNA expression data: ')\n",
    "print(f'Studies: {len(studies_transcriptomes_sorted_ma_seq_experiments)}')\n",
    "print(f'Experiments: {len(experiment_transcriptomes_sorted_ma_seq_experiments)}')\n",
    "print(f'Subjects: ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expsample_gene_expr = pd.merge(expsample, gene_expression, on='EXPSAMPLE_ACCESSION', how='inner')\n",
    "expsample_gene_expr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter only for valid experiments! \n",
    "expsample_gene_expr_bulk_transriptomes = expsample_gene_expr[expsample_gene_expr['EXPERIMENT_ACCESSION'].isin(experiment_transcriptomes_sorted_ma_seq_experiments)]\n",
    "print(expsample_gene_expr_bulk_transriptomes.shape)\n",
    "print(expsample_gene_expr_bulk_transriptomes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_w_age.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Kills the kernel\n",
    "\"\"\" subject_w_age['WORKSPACE_ID'] = subject_w_age['WORKSPACE_ID'].astype(int)\n",
    "expsample_gene_expr_bulk_transriptomes_w_age = pd.merge(expsample_gene_expr_bulk_transriptomes, subject_w_age, on='WORKSPACE_ID', how='inner')\n",
    "print(expsample_gene_expr_bulk_transriptomes_w_age.columns)\n",
    "expsample_gene_expr_bulk_transriptomes_w_age.head() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biosample_subject_accession = biosample[['BIOSAMPLE_ACCESSION', 'SUBJECT_ACCESSION']]\n",
    "mapping_df_biosample_expsample = pd.merge(expsample_2_biosample, biosample_subject_accession, on='BIOSAMPLE_ACCESSION', how='inner')\n",
    "print(mapping_df_biosample_expsample.columns)\n",
    "\n",
    "\n",
    "expsample_gene_expr_bulk_transriptomes_mapping = pd.merge(expsample_gene_expr_bulk_transriptomes, mapping_df_biosample_expsample, on='EXPSAMPLE_ACCESSION', how='inner')\n",
    "print(expsample_gene_expr_bulk_transriptomes.columns)\n",
    "\n",
    "subject_w_age['WORKSPACE_ID'] = subject_w_age['WORKSPACE_ID'].astype(int)\n",
    "expsample_gene_expr_bulk_transriptomes_mapping['WORKSPACE_ID'] = expsample_gene_expr_bulk_transriptomes_mapping['WORKSPACE_ID'].astype(int)\n",
    "expsample_gene_expr_bulk_transriptomes_w_subjects = pd.merge(expsample_gene_expr_bulk_transriptomes_mapping, subject_w_age, on='SUBJECT_ACCESSION', how='inner') \n",
    "print(expsample_gene_expr_bulk_transriptomes_w_subjects.columns)\n",
    "expsample_gene_expr_bulk_transriptomes_w_subjects.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = expsample_gene_expr_bulk_transriptomes_w_subjects.groupby('SUBJECT_ACCESSION')['REPOSITORY_ACCESSION'].count()\n",
    "counts_df = counts.reset_index(name='count')\n",
    "\n",
    "counts_df.describe()\n",
    "max_outlier = counts_df[counts_df['count']>= 500]\n",
    "max_outlier\n",
    "#expsample_gene_expr_bulk_transriptomes_w_subjects[expsample_gene_expr_bulk_transriptomes_w_subjects['SUBJECT_ACCESSION'] == 'SUB134248']['EXPSAMPLE_ACCESSION'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape expsamples {expsample_gene_expr_bulk_transriptomes_w_subjects.shape}')\n",
    "subjects_unique_df = expsample_gene_expr_bulk_transriptomes_w_subjects.drop_duplicates('SUBJECT_ACCESSION', keep='first')\n",
    "print(subjects_unique_df.shape)\n",
    "subjects_unique_list = expsample_gene_expr_bulk_transriptomes_w_subjects['SUBJECT_ACCESSION'].unique()\n",
    "print(f'Subjects {len(subjects_unique_list)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='GENDER', y='MAX_SUBJECT_AGE_IN_YEARS', hue='GENDER', data=subjects_unique_df[['GENDER', 'MAX_SUBJECT_AGE_IN_YEARS']], split=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This seems to kill my kernel all over again. \n",
    "#expsample_gene_expr_bulk_transriptomes_w_subject = pd.merge(expsample_gene_expr_bulk_transriptomes, subject, on='WORKSPACE_ID', how='left')\n",
    "#expsample_gene_expr_bulk_transriptomes_w_subject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expsample_gene_expr_bulk_transriptomes_w_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expsample_gene_expr_bulk_transriptomes_w_subjects['REPOSITORY_ACCESSION'].unique()\n",
    "#### GEO: GSM specifies a sample usually\n",
    "### Test GEO: GSM1885263 ; Test SRA: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expsample_gene_expr_bulk_transriptomes_w_subjects['REPOSITORY_NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### As we only get GSM IDs i need a script to automatically download stuff from GEO (and maybe the other platforms too  ?)\n",
    "from Bio import Entrez\n",
    "\n",
    "# Set your email address for NCBI Entrez\n",
    "Entrez.email = \"elias.schreiner@uni-tuebingen.de\"\n",
    "\n",
    "# Function to search for datasets on GEO\n",
    "def search_geo(query):\n",
    "    handle = Entrez.esearch(db=\"gds\", term=query, retmax=10)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record[\"IdList\"]\n",
    "\n",
    "# Function to download datasets by accession number\n",
    "def download_geo(accession):\n",
    "    handle = Entrez.efetch(db=\"gds\", id=accession, rettype=\"xml\")\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    # Extract download links from the record and download the datasets\n",
    "    for link in record[0][\"EXPERIMENT_PACKAGE\"][\"SUPPLEMENTARY_FILE\"]:\n",
    "        url = link[\"@url\"]\n",
    "        filename = os.path.basename(url)\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        os.system(f\"wget {url}\")\n",
    "\n",
    "accession_list = search_geo('GSM1885263')\n",
    "print(accession_list)\n",
    "#download_geo(accession_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
